---
title: "Cross Validation"
author: "Mahdi Maktabi"
date: "Nov 12, 2024"
output: github_document
---

Load key packages.

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(mgcv)
library(SemiPar)

set.seed(1) # this just makes it so any time we rerun a code it will give the same random results
```

Look at LIDAR data

```{r}
data("lidar")

lidar_df = 
  lidar |> 
  as_tibble() |> 
  mutate(id = row_number())
```

```{r}
lidar_df |> 
  ggplot(aes(x = range, y = logratio)) +
  geom_point()
```

## Try to do CV

We will compare 3 model -- one linear, one smooth, one wiggly.

Construct training and testing df.

```{r}
train_df = sample_frac(lidar_df, size = .8)
test_df = anti_join(lidar_df, train_df, by = "id")
```

Look at these - this will overlay the one with the missing points and then overlay the points in red.

```{r}
ggplot(train_df, aes(x = range, y = logratio)) +
  geom_point() +
  geom_point(data = test_df, color = "red")
```

Fit three models.

```{r}
linear_mod = lm(logratio ~ range, data = train_df)
smooth_mod = gam(logratio ~ s(range), data = train_df)
wiggly_mod = gam(logratio ~ s(range, k = 30), sp = 10e-6, data = train_df)
```

Look at these fits.

```{r}
train_df |> 
  add_predictions(linear_mod) |> 
  ggplot(aes(x = range, y = logratio)) +
  geom_point() +
  # geom_point(data = test_df, color = "red") +
  geom_line(aes(y = pred), color = "red")
```

```{r}
train_df |> 
  add_predictions(wiggly_mod) |> 
  ggplot(aes(x = range, y = logratio)) +
  geom_point() +
  geom_point(data = test_df, color = "red") +
  geom_line(aes(y = pred), color = "red")
```

```{r}
train_df |> 
  add_predictions(smooth_mod) |> 
  ggplot(aes(x = range, y = logratio)) +
  geom_point() +
  geom_point(data = test_df, color = "red") +
  geom_line(aes(y = pred), color = "red")
```

Smooth model doesn't do too much - captures the trends we are looking for ("just right").


Now compare these numerically using RMSE.

```{r}
rmse(linear_mod, test_df)
rmse(smooth_mod, test_df)
rmse(wiggly_mod, test_df)
```

## Repeat the train / test split

```{r}
cv_df = 
  crossv_mc(lidar_df, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )
```

```{r, eval=FALSE}
cv_df |> 
  pull(train) |> 
  nth(2) |> 
  as_tibble()
```

Fit models, extract RMSEs

```{r}
cv_results_df = 
  cv_df |> 
  mutate(
    linear_mod = map(train, \(x) lm(logratio ~ range, data = x)),
    smooth_mod = map(train, \(x) gam(logratio ~ s(range), data = x)),
    wiggly_mod = map(train, \(x) gam(logratio ~ s(range, k = 30), sp = 10e-6, data = x))
  ) |> 
  mutate(
    rmse_linear = map2_dbl(linear_mod, test, rmse),
    rmse_smooth = map2_dbl(smooth_mod, test, rmse),
    rmse_wiggly = map2_dbl(wiggly_mod, test, rmse)
    )
```

Look at RMSE distribution

```{r}
cv_results_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) |> 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin()
```

## Nepalese children DF

```{r}
child_df = 
  read_csv("data/nepalese_children.csv") |> 
  mutate(
    weight_ch7 = (weight > 7) * (weight - 7)
  )
```

Look at the data.

```{r}
child_df |> 
  ggplot(aes(x = weight, y = armc)) +
  geom_point(alpha = .5)
```

Fit some models.

```{r}
linear_mod = lm(armc ~ weight, data = child_df)
pwl_mod = lm(armc ~ weight + weight_ch7, data = child_df)
smooth_mod = gam(armc ~ s(weight), data = child_df)
```

```{r}
child_df |> 
  add_predictions(linear_mod) |> 
  ggplot(aes(x = weight, y = armc)) +
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = "red")
```

```{r}
child_df |> 
  add_predictions(pwl_mod) |> 
  ggplot(aes(x = weight, y = armc)) +
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = "red")
```

```{r}
child_df |> 
  add_predictions(smooth_mod) |> 
  ggplot(aes(x = weight, y = armc)) +
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = "red")
```

